# -*- coding: utf-8 -*-
"""pdf_to_text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GKX81rWbbFGPStc8LAX-f53F1KAXA6kb
"""

# Commented out IPython magic to ensure Python compatibility.
# install dependencies,to install you can uncomment the comment lines below.
# !pip install layoutparser
# !pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'
# !pip install layoutparser[ocr]
# !sudo apt-get install poppler-utils
# !sudo apt install tesseract-ocr

import logging
from time import time

import layoutparser as lp
import numpy as np
import pandas as pd
from pdf2image import convert_from_path, pdfinfo_from_path
from sklearn.cluster import DBSCAN
from tqdm.auto import tqdm

log = logging.getLogger()


def pdf_to_text(pdf, output_file="output.txt"):
    """
    pdf: path to the pdf that you want to extract.
    output_file: output of  the text file
    """
    log.info(f"started {pdf}")
    start = time()
    images = convert_from_path(pdf, fmt="jpeg")
    log.info(f"got pdf {round(time()-start)}")
    start = time()

    model = lp.Detectron2LayoutModel(
        "lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config",
        extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.8],
        label_map={0: "Text", 1: "Title", 2: "List", 3: "Table", 4: "Figure"},
    )
    log.info(f"got model {round(time()-start)}")
    start = time()

    all_text = []
    for i, image in tqdm(enumerate(images)):
        # get layout
        image = np.array(image)
        layout = model.detect(image)

        # filter
        text_blocks = lp.Layout([b for b in layout if b.type == "Text"])
        figure_blocks = lp.Layout([b for b in layout if b.type == "Figure"])
        text_blocks = lp.Layout(
            [
                b
                for b in text_blocks
                if not any(b.is_in(b_fig) for b_fig in figure_blocks)
            ]
        )

        # OCR
        ocr_agent = lp.TesseractAgent(languages="eng")
        for block in text_blocks:
            segment_image = block.pad(left=5, right=5, top=5, bottom=5).crop_image(
                image
            )
            text = ocr_agent.detect(segment_image)
            block.set(text=text, inplace=True)

        # cluster columns
        df = pd.DataFrame()
        df["text"] = [b.text for b in text_blocks]
        df[["x0", "y0", "x1", "y1"]] = [b.coordinates for b in text_blocks]
        db = DBSCAN(eps=15, min_samples=1)
        df["cluster"] = db.fit_predict(np.array(df.x0.values).reshape(-1, 1))
        df["x0group"] = df.groupby("cluster").x0.transform(np.median).astype(int)
        df = df.sort_values(["x0group", "y0"])

        text = (
            "\n".join(df.text.values)
            + f"\n_____________________________________________page{i+1}____________________________________\n"
        )
        text = text.replace("\f", "")
        all_text.append(text)

    log.info(f"got OCR text {round(time()-start)}")
    start = time()

    with open(output_file, "w") as text_file:
        for text in all_text:
            text_file.write(text)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    pdf_to_text("/mnt/d/data1/Boskalis_Sustainability_Report_2020.pdf")
